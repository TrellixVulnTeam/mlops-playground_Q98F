{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 목표\n",
    "* **XGBoost**의 훈련, 파리미터 튜닝, 배포 과정을 **Amazon SageMaker** 빌트인 알고리즘을 이용하여 진행해본다.\n",
    "* (선택) SageMaker **HyperparameterTuner**을 사용해서 하이퍼파라미터 튜닝하고 결과를 분석, 시각화해본다.\n",
    "\n",
    "# 요구사항\n",
    "* 여기서 사용한 이상거래 탐지 데이터셋은 [해당 Kaggle 대회](https://www.kaggle.com/c/ieee-fraud-detection)에서 다운로드 받을 수 있다.\n",
    "* `scikit-learn` 버전 0.24 이상과 `category_encoders`가 설치되어야 한다. `bokeh` 플롯을 SVG 형식으로 저장하려면 `selenium`, `geckodriver` 설치가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bokeh.io import export_png, export_svgs\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import Band, ColumnDataSource, HoverTool, NumeralTickFormatter\n",
    "from bokeh.plotting import figure, show\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n",
    "                             average_precision_score, precision_recall_curve, roc_auc_score, roc_curve)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.tuner import CategoricalParameter, ContinuousParameter, IntegerParameter, HyperparameterTuner\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(score, thr=0.5):\n",
    "    return np.where(score >= thr, 1, 0)\n",
    "\n",
    "\n",
    "def is_number(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return 1\n",
    "    except:\n",
    "        return 0 \n",
    "\n",
    "\n",
    "def make_dirs(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "\n",
    "def str_to_int(x):\n",
    "    return x if pd.isnull(x) else str(int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기\n",
    "Kaggle 데이터셋을 로컬 디렉토리 `../../Data/ieee-fraud-detection`에 미리 저장해두었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = '../../Data/ieee-fraud-detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identity = pd.read_csv(os.path.join(RAW_DATA_PATH, 'train_identity.csv'))\n",
    "train_transaction = pd.read_csv(os.path.join(RAW_DATA_PATH, 'train_transaction.csv'))\n",
    "df_train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "범주형 변수의 목록과 설명은 [해당 페이지](https://www.kaggle.com/c/ieee-fraud-detection/data)에서 살펴볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = pd.Index(\n",
    "    ['ProductCD', 'addr1', 'addr2', 'P_emaildomain', 'R_emaildomain', 'DeviceType', 'DeviceInfo'] + [\n",
    "        f'card{i}' for i in range(1, 7)] + [f'M{i}' for i in range(1, 10)] + [f'id_{i}' for i in range(12, 39)])\n",
    "num_features = df_train.columns.difference(pd.Index(['TransactionID', 'TransactionDT', 'isFraud']) | cat_features)\n",
    "all_features = cat_features | num_features\n",
    "\n",
    "int_cat_features =  df_train[cat_features].select_dtypes('number').columns\n",
    "df_train[int_cat_features] = df_train[int_cat_features].applymap(str_to_int)\n",
    "df_train[cat_features] = df_train[cat_features].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 분할과 전처리\n",
    "데이터셋을 76.5%, 13.5%, 10%씩 나눠서 훈련 셋, 검증 셋, 시험 셋을 할당하였다. XGBoost의 경우 알고리즘 내부에서 범주형 변수를 별도 처리하는 로직이 없으므로 미리 전처리를 해줘야한다. 그러므로 범주형 변수에 서수형 인코딩과 결측값 처리를 한 다음 타겟 인코딩을 추가 적용하였다. 수치형 변수에는 결측값 처리만 적용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train, df_X_test, df_y_train, df_y_test = train_test_split(\n",
    "    df_train[all_features], df_train['isFraud'], test_size=0.1, random_state=42, stratify=df_train['isFraud'])\n",
    "\n",
    "df_X_train, df_X_valid, df_y_train, df_y_valid = train_test_split(\n",
    "    df_X_train, df_y_train, test_size=0.15, random_state=42, stratify=df_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mlops-playground/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "cat_pipeline = make_pipeline(OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan),\n",
    "                             SimpleImputer(strategy='constant', fill_value=-1), TargetEncoder(min_samples_leaf=1, smoothing=1.0))\n",
    "num_pipeline = SimpleImputer(strategy='median')\n",
    "processor = make_column_transformer((cat_pipeline, cat_features), (num_pipeline, num_features))\n",
    "\n",
    "X_train = processor.fit_transform(df_X_train, df_y_train)\n",
    "X_valid = processor.transform(df_X_valid)\n",
    "X_test = processor.transform(df_X_test)\n",
    "\n",
    "dtrain = np.concatenate((df_y_train.values.reshape(-1, 1), X_train), axis=1)\n",
    "dvalid = np.concatenate((df_y_valid.values.reshape(-1, 1), X_valid), axis=1)\n",
    "dtest = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data_path = './dataset'\n",
    "dir_names = ['train', 'valid', 'test']\n",
    "file_names = ['dtrain', 'dvalid', 'dtest']\n",
    "\n",
    "for dir_name in dir_names:\n",
    "    make_dirs(os.path.join(proc_data_path, dir_name))\n",
    "\n",
    "for dir_name, file_name, dataset in zip(dir_names, file_names, [dtrain, dvalid, dtest]):\n",
    "    np.savetxt(os.path.join(PROC_DATA_PATH, dir_name, file_name) + '.csv', dataset, delimiter=',', fmt='%i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하이퍼파라미터 튜닝\n",
    "### S3 버킷에 데이터셋 업로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = sagemaker_session.default_bucket()\n",
    "PREFIX = 'ieee-fraud-detection'\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "for dir_name, file_name in zip(dir_names, file_names):\n",
    "    s3_client.upload_file(\n",
    "        os.path.join(PROC_DATA_PATH, PREFIX, file_name) + '.csv', BUCKET, PREFIX + '/' + dir_name + '/' + file_name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 빌트인 알고리즘 XGBoost Estimator 구성\n",
    "`XGBoost`는 1.2.1 버전 이미지를 이용했고 하이퍼파라미터 종류와 범위는 [해당 페이지](https://xgboost.readthedocs.io/en/latest/parameter.html)를 참조하여 설정하였다. 대회 기준인 AUROC로 검증 셋을 평가하여 조기 종료 가능하게끔 지정했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_weight = float(df_y_train.shape[0] / df_y_train.sum() - 1.0)\n",
    "\n",
    "model_output_uri = f's3://{BUCKET}/{PREFIX}/models'\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='xgboost',\n",
    "    region=region,\n",
    "    version='1.2-1',\n",
    "    py_version='py3',\n",
    "    instance_type='ml.m5.2xlarge'\n",
    ")\n",
    "\n",
    "clf = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.2xlarge',\n",
    "    output_path=model_output_uri,\n",
    "    use_spot_instances=False,\n",
    "    max_wait=None\n",
    ")\n",
    "clf.set_hyperparameters(\n",
    "    booster='gbtree',\n",
    "    verbosity=0,\n",
    "    objective='binary:logistic',\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    seed=42,\n",
    "    eval_metric='auc',\n",
    "    num_round=1000,\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperparameterTuner 구성과 실행\n",
    "베이지안 최적화 과정을 30번 수행하여 최적 파라미터를 찾게끔 설정했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'max_depth': IntegerParameter(1, 30),\n",
    "    'eta': ContinuousParameter(0.01, 1.0),\n",
    "    'gamma': ContinuousParameter(0.0, 1.0),\n",
    "    'min_child_weight': ContinuousParameter(1e-06, 1.0),\n",
    "    'subsample': ContinuousParameter(0.1, 1.0),\n",
    "    'colsample_bytree': ContinuousParameter(0.1, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    clf,\n",
    "    'validation:auc',\n",
    "    hyperparameter_ranges,\n",
    "    objective_type='Maximize',\n",
    "    max_jobs=30,\n",
    "    max_parallel_jobs=3,\n",
    "    base_tuning_job_name='ifd-xgb-hpo',\n",
    "    early_stopping_type='Off'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = TrainingInput(\n",
    "    s3_data=f's3://{BUCKET}/{prefix}/train/', \n",
    "    content_type='text/csv'\n",
    ")\n",
    "valid_input = TrainingInput(\n",
    "    s3_data=f's3://{BUCKET}/{prefix}/valid/', \n",
    "    content_type='text/csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tuner.fit(\n",
    "    {\n",
    "        'train': train_input, \n",
    "        'validation': valid_input\n",
    "    }\n",
    ")\n",
    "\n",
    "best_clf = tuner.best_estimator()\n",
    "best_params = best_clf.hyperparameters()\n",
    "tuning_job_name = tuner.latest_tuning_job.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 튜닝 결과 분석과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_analytics = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "df_viz = tuning_job_analytics.dataframe()\n",
    "\n",
    "image_path = './images'\n",
    "make_dirs(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz.sort_values('FinalObjectiveValue', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HoverHelper():\n",
    "    def __init__(self, tuning_job_analytics):\n",
    "        self.tuning_job_analytics = tuning_job_analytics\n",
    "\n",
    "    def hovertool(self):\n",
    "        tooltips = [\n",
    "            ('TrainingJobName', '@TrainingJobName'),\n",
    "            ('FinalObjectiveValue', '@FinalObjectiveValue')\n",
    "        ]\n",
    "    \n",
    "        for key in self.tuning_job_analytics.tuning_ranges.keys():\n",
    "            tooltips.append((key, '@{%s}' % key) )\n",
    "\n",
    "        hover_tool = HoverTool(tooltips=tooltips)\n",
    "        return hover_tool\n",
    "\n",
    "    def tools(self, standard_tools='pan, crosshair, wheel_zoom, zoom_in, zoom_out, undo, reset'):\n",
    "        return [self.hovertool(), standard_tools]\n",
    "    \n",
    "    \n",
    "def make_grid(figures, n_cols):\n",
    "    rows = []\n",
    "    for i, figure in enumerate(figures):\n",
    "        if i % n_cols == 0:\n",
    "            cols = []\n",
    "        elif (i % n_cols == n_cols - 1) or i == (len(figures) - 1):\n",
    "            rows.append(cols)\n",
    "        cols.append(figure)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hover_helper = HoverHelper(tuning_job_analytics)\n",
    "\n",
    "p = figure(plot_width=800, plot_height=400, tools=hover_helper.tools(), \n",
    "           title='Convergence Plot', x_axis_type='datetime', x_axis_label='Training Start Time', y_axis_label='AUROC')\n",
    "_ = p.line(source=df_viz, x='TrainingStartTime', y='FinalObjectiveValue', color='coral', line_width=1.5)\n",
    "_ = p.circle(source=df_viz, x='TrainingStartTime', y='FinalObjectiveValue', line_color='coral', line_width=1.5, fill_color='white')\n",
    "\n",
    "p.title.align = 'center'\n",
    "p.title.text_font_size = '11pt'\n",
    "p.xgrid.grid_line_color = None\n",
    "p.yaxis.formatter = NumeralTickFormatter(format='0.0%')\n",
    "\n",
    "show(p)\n",
    "\n",
    "p.output_backend = 'svg'\n",
    "_ = export_svgs(p, filename=f'{image_path}/convergence_plot.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz = df_viz.reset_index()\n",
    "df_viz['index'] = (df_viz['index'] + df_viz['index'].min()) / (df_viz['index'].max() - df_viz['index'].min())\n",
    "\n",
    "figures = []\n",
    "for param_name, param_range in tuning_job_analytics.tuning_ranges.items():\n",
    "    categorical_args = dict()\n",
    "    if param_range.get('Values'):          \n",
    "        values = param_range['Values']\n",
    "        if sum([is_number(x) for x in values]) == len(values):\n",
    "            print(\"Hyperparameter %s is tuned as categorical, but all values are numeric.\" % param_name)\n",
    "        else:\n",
    "            categorical_args['x_range'] = values\n",
    "\n",
    "    plot = figure(plot_width=400, plot_height=400, tools=hover_helper.tools(), \n",
    "               x_axis_label=param_name, y_axis_label='AUROC', **categorical_args)\n",
    "    plot.circle(source=df_viz, x=param_name, y='FinalObjectiveValue', color='black', alpha='index')\n",
    "    plot.xgrid.grid_line_color = None\n",
    "    plot.yaxis.formatter = NumeralTickFormatter(format='0.0%')\n",
    "    figures.append(plot)\n",
    "\n",
    "p = gridplot(make_grid(figures, 3), toolbar_location='right')\n",
    "\n",
    "show(p)\n",
    "\n",
    "_ = export_png(p, filename=f'{image_path}/partial_dependence_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시험 셋 평가\n",
    "### Transformer 구성과 예측 점수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "transformer = best_clf.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.2xlarge', \n",
    "    output_path=f's3://{BUCKET}/{PREFIX}/prediction'\n",
    ")\n",
    "\n",
    "_ = transformer.transform(\n",
    "    data=f's3://{BUCKET}/{PREFIX}/test/',\n",
    "    content_type='text/csv', \n",
    "    split_type='Line'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.download_file(BUCKET, f'{PREFIX}/prediction/dtest.csv.out', os.path.join(proc_data_path, 'test', 'dtest.csv.out'))\n",
    "scores = pd.read_csv(os.path.join(proc_data_path, 'test', 'dtest.csv.out'), header=None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = get_pred(scores)\n",
    "\n",
    "print('Accuracy: {0:.2%}, Precision: {1:.2%}, Recall: {2:.2%}, F1: {3:.2%}'.format(\n",
    "    accuracy_score(df_y_test, preds), precision_score(df_y_test, preds), recall_score(df_y_test, preds), f1_score(df_y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.DataFrame(roc_curve(df_y_test, scores), index=['fpr', 'tpr', 'thr']).T\n",
    "\n",
    "p = figure(plot_height=400, title='ROC Curve (AUROC {:.2%})'.format(roc_auc_score(df_y_test, scores)), \n",
    "           x_axis_label='False Positive Rate', y_axis_label='True Positive Rate')\n",
    "_ = p.line(source=source, x='fpr', y='tpr', color='coral', line_width=1.5)\n",
    "_ = p.line(source=source, x='fpr', y='fpr', color='black', line_dash='dashed')\n",
    "\n",
    "p.title.align = 'center'\n",
    "p.title.text_font_size = '11pt'\n",
    "p.xgrid.grid_line_color = None\n",
    "p.xaxis.formatter = NumeralTickFormatter(format='0.0%')\n",
    "p.yaxis.formatter = NumeralTickFormatter(format='0.0%')\n",
    "\n",
    "show(p)\n",
    "\n",
    "p.output_backend = 'svg'\n",
    "_ = export_svgs(p, filename=f'{image_path}/roc_curve.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.DataFrame(precision_recall_curve(df_y_test, scores), index=['recall', 'precision', 'thr']).T\n",
    "\n",
    "p = figure(plot_height=400, title='Precision - Recall Curve (AUPRC {:.2%})'.format(average_precision_score(df_y_test, scores)), \n",
    "           x_axis_label='Recall', y_axis_label='Precision')\n",
    "_ = p.line(source=source, x='recall', y='precision', color='coral', line_width=1.0)\n",
    "band = Band(source=ColumnDataSource(data=dict(recall=source['recall'], precision=source['precision'])), \n",
    "            base='recall', upper='precision', level='underlay', fill_alpha=0.2, fill_color='coral')\n",
    "p.add_layout(band)\n",
    "\n",
    "p.title.align = 'center'\n",
    "p.title.text_font_size = '11pt'\n",
    "p.xgrid.grid_line_color = None\n",
    "p.xaxis.formatter = NumeralTickFormatter(format='0.0%')\n",
    "p.yaxis.formatter = NumeralTickFormatter(format='0.0%')\n",
    "\n",
    "show(p)\n",
    "\n",
    "p.output_backend = 'svg'\n",
    "_ = export_svgs(p, filename=f'{image_path}/pr_curve.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 적합과 배포\n",
    "Kaggle 대회에 제출할 퀴즈 셋을 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_identity = pd.read_csv(os.path.join(RAW_DATA_PATH, 'test_identity.csv')) \n",
    "test_transaction = pd.read_csv(os.path.join(RAW_DATA_PATH, 'test_transaction.csv'))\n",
    "df_test = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')\n",
    "df_test = df_test.rename(columns={'id-{:02d}'.format(i): 'id_{:02d}'.format(i) for i in range(1, 39)})\n",
    "\n",
    "df_test[int_cat_features] = df_test[int_cat_features].applymap(str_to_int)\n",
    "df_test[cat_features] = df_test[cat_features].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train, df_X_valid, df_y_train, df_y_valid = train_test_split(\n",
    "    df_train[all_features], df_train['isFraud'], test_size=0.15, random_state=42, stratify=df_train['isFraud'])\n",
    "\n",
    "X_train = processor.fit_transform(df_X_train, df_y_train)\n",
    "X_valid = processor.transform(df_X_valid)\n",
    "X_test = processor.transform(df_test[all_features])\n",
    "\n",
    "dtrain = np.concatenate((df_y_train.values.reshape(-1, 1), X_train), axis=1)\n",
    "dvalid = np.concatenate((df_y_valid.values.reshape(-1, 1), X_valid), axis=1)\n",
    "dtest = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_name in dir_names:\n",
    "    make_dirs(os.path.join(PROC_DATA_PATH, dir_name))\n",
    "\n",
    "for dir_name, file_name, dataset in zip(dir_names, file_names, [dtrain, dvalid, dtest]):\n",
    "    np.savetxt(os.path.join(proc_data_path, dir_name, file_name) + '.csv', dataset, delimiter=',', fmt='%i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for dir_name, file_name in zip(dir_names, file_names):\n",
    "    s3_client.upload_file(\n",
    "        os.path.join(proc_data_path, dir_name, file_name) + '.csv', BUCKET, PREFIX + '/' + dir_name + '/' + file_name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_params = best_clf.hyperparameters()\n",
    "_ = best_params.pop('_tuning_objective_metric')\n",
    "\n",
    "params = clf.hyperparameters()\n",
    "params.update(best_params)\n",
    "clf.set_hyperparameters(**params)\n",
    "\n",
    "clf.fit(\n",
    "    {\n",
    "    'train': train_input,\n",
    "    'validation': valid_input\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "transformer = clf.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.2xlarge', \n",
    "    output_path=f's3://{BUCKET}/{PREFIX}/prediction'\n",
    ")\n",
    "\n",
    "_ = transformer.transform(\n",
    "    data=f's3://{BUCKET}/{PREFIX}/test/',\n",
    "    content_type='text/csv', \n",
    "    split_type='Line'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.download_file(BUCKET, f'{PREFIX}/prediction/dtest.csv.out', os.path.join(proc_data_path, 'test', 'dtest.csv.out'))\n",
    "scores = pd.read_csv(os.path.join(proc_data_path, 'test', 'dtest.csv.out'), header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'TransactionID': df_test['TransactionID'].values, 'isFraud': scores.flatten()})\n",
    "submission.to_csv('./submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
